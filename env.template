# FintelligenceAI Environment Configuration Template
# Copy this file to .env and fill in your actual values
# This file works for both local development and Docker deployment

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
APP_NAME=FintelligenceAI
APP_VERSION=0.1.0
APP_ENVIRONMENT=development  # development, staging, production
APP_DEBUG=true
APP_LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true  # Set to false in production
API_WORKERS=1  # Number of workers for production

# =============================================================================
# DOCKER PORT MAPPINGS (Host machine ports)
# =============================================================================
# These control which ports are exposed on your host machine when using Docker
UI_PORT=3000              # Port for accessing the web UI
POSTGRES_PORT=5432        # PostgreSQL database port (dev mode only)
REDIS_PORT=6379          # Redis port (dev mode only)
CHROMA_PORT=8100         # ChromaDB vector database port
PROMETHEUS_PORT=9090     # Prometheus metrics port
GRAFANA_PORT=3001        # Grafana dashboard port
OLLAMA_PORT=11434        # Ollama local LLM port
ADMINER_PORT=8080        # Database admin interface (dev mode only)
REDIS_COMMANDER_PORT=8081 # Redis admin interface (dev mode only)
NGINX_HTTP_PORT=80       # Nginx HTTP port (production mode)
NGINX_HTTPS_PORT=443     # Nginx HTTPS port (production mode)

# =============================================================================
# LANGUAGE MODEL PROVIDERS
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini  # gpt-4, gpt-4o-mini, gpt-3.5-turbo
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=4096
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# Anthropic Claude (Fallback)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Local Model Configuration
# For Docker: use container name "ollama"
# For local development: use "localhost"
OLLAMA_BASE_URL=http://localhost:11434  # Change to http://ollama:11434 when using Docker with local-ai profile
OLLAMA_MODEL=llama3.2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_TEMPERATURE=0.1
OLLAMA_MAX_TOKENS=4096

# =============================================================================
# VECTOR DATABASE CONFIGURATION
# =============================================================================

# ChromaDB Configuration
# For Docker: use container name "chromadb"
# For local development: use "localhost"
CHROMA_HOST=localhost  # Automatically set to "chromadb" in Docker Compose
CHROMA_PORT=8000       # Internal container port (different from CHROMA_PORT above)
CHROMA_PERSIST_DIRECTORY=./data/chroma  # Will be mapped to Docker volume
CHROMA_COLLECTION_NAME=fintelligence_ai

# Pinecone Configuration (Production alternative to ChromaDB)
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=us-west1-gcp-free
PINECONE_INDEX_NAME=fintelligence-ai

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# PostgreSQL Configuration
# For Docker: use container name "postgres"
# For local development: use "localhost"
POSTGRES_USER=fintelligence_user
POSTGRES_PASSWORD=your_secure_password_here  # Change this to a secure password!
POSTGRES_DB=fintelligence_ai
POSTGRES_HOST=localhost  # Automatically set to "postgres" in Docker Compose
POSTGRES_PORT=5432

# Database URL (constructed from above values)
# This will be automatically adjusted for Docker containers
DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}

# =============================================================================
# REDIS CONFIGURATION
# =============================================================================
# For Docker: use container name "redis"
# For local development: use "localhost"
REDIS_HOST=localhost  # Automatically set to "redis" in Docker Compose
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=  # Leave empty if no password
REDIS_URL=redis://${REDIS_HOST}:${REDIS_PORT}/${REDIS_DB}

# =============================================================================
# EXTERNAL API INTEGRATIONS
# =============================================================================

# GitHub API Configuration (for knowledge base ingestion)
GITHUB_TOKEN=your_github_personal_access_token_here
# Generate at: https://github.com/settings/tokens
# Required scopes: public_repo (for public repositories)

# =============================================================================
# ERGO BLOCKCHAIN INTEGRATION
# =============================================================================

# Ergo Node Configuration
ERGO_NODE_URL=http://localhost:9052
ERGO_NODE_API_KEY=your_ergo_node_api_key_here
ERGO_EXPLORER_URL=https://api.ergoplatform.com

# =============================================================================
# DSPy CONFIGURATION
# =============================================================================

# DSPy Model Settings
DSPY_LOCAL_MODE=false  # Set to true for local-only mode (no API keys required)
DSPY_MODEL_PROVIDER=openai  # openai, anthropic, ollama
DSPY_CACHE_DIR=./data/dspy_cache      # Will be mapped to Docker volume
DSPY_EXPERIMENT_DIR=./data/experiments # Will be mapped to Docker volume

# Optimization Settings
DSPY_OPTIMIZER=MIPROv2  # MIPROv2, BootstrapFinetune, Random
DSPY_TRAINING_SIZE=100
DSPY_VALIDATION_SIZE=50
DSPY_MAX_ITERATIONS=50

# =============================================================================
# MONITORING AND OBSERVABILITY
# =============================================================================

# Grafana Configuration (Docker)
GRAFANA_USER=admin
GRAFANA_PASSWORD=admin  # Change this to a secure password!

# LangSmith Configuration
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=fintelligence-ai

# Sentry Configuration (Production)
SENTRY_DSN=your_sentry_dsn_here
SENTRY_ENVIRONMENT=development

# Prometheus Metrics
METRICS_ENABLED=true
METRICS_PORT=9090

# =============================================================================
# SECURITY AND AUTHENTICATION
# =============================================================================

# JWT Configuration
JWT_SECRET_KEY=your_very_secret_jwt_key_here_use_strong_random_string  # Change this to a secure random string!
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=30

# API Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_CALLS=100
RATE_LIMIT_PERIOD=60  # seconds

# CORS Configuration
# For Docker: include both localhost and container names
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8080", "http://fintelligence-ui"]
CORS_ALLOW_CREDENTIALS=true

# =============================================================================
# FILE STORAGE AND PROCESSING
# =============================================================================

# Local File Storage
# For Docker: these paths will be mapped to volumes
UPLOAD_DIR=./data/uploads  # Will be mapped to Docker volume
MAX_FILE_SIZE=10485760  # 10MB in bytes
ALLOWED_FILE_TYPES=["pdf", "txt", "md", "json"]

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_DOCS_PER_QUERY=10

# =============================================================================
# DEVELOPMENT AND TESTING
# =============================================================================

# Development Tools
ENABLE_RELOAD=true
ENABLE_PROFILING=false
ENABLE_DEBUG_TOOLBAR=false

# Testing Configuration
TEST_DATABASE_URL=postgresql+asyncpg://test_user:test_pass@localhost:5432/test_fintelligence_ai
TEST_OPENAI_API_KEY=your_test_openai_api_key_here

# =============================================================================
# PRODUCTION SETTINGS
# =============================================================================

# Production Security
SECURE_COOKIES=false  # Set to true in production with HTTPS
HTTPS_ONLY=false  # Set to true in production

# Production Performance
WORKER_PROCESSES=4
WORKER_CONNECTIONS=1000
KEEPALIVE_TIMEOUT=5

# Logging Configuration
LOG_FORMAT=json  # json, text
LOG_FILE=./logs/fintelligence_ai.log  # Will be mapped to Docker volume
LOG_ROTATION=daily
LOG_RETENTION_DAYS=30

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================

# Feature Flags
ENABLE_ADVANCED_RAG=true
ENABLE_MULTI_AGENT=true
ENABLE_REALTIME_OPTIMIZATION=false
ENABLE_CUSTOM_EMBEDDINGS=false

# Experimental Model Providers
ENABLE_LOCAL_MODELS=false
ENABLE_CUSTOM_ENDPOINTS=false
